# =================================================================
# Spike-SNN Event Vision Kit - Environment Configuration Template
# =================================================================
# Copy this file to .env and configure according to your setup
# 
# NEVER commit .env files to version control!
# This file contains default values and documentation

# =================================================================
# DEVELOPMENT ENVIRONMENT
# =================================================================

# Development mode (affects logging, debugging, model checkpointing)
DEVELOPMENT_MODE=true

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Enable debug mode for detailed tracing
DEBUG=false

# =================================================================
# HARDWARE CONFIGURATION
# =================================================================

# Primary compute device (cpu, cuda, mps)
DEVICE=cuda

# CUDA device ID (0, 1, 2, etc.) - only used if DEVICE=cuda
CUDA_DEVICE_ID=0

# Enable mixed precision training (true/false)
ENABLE_MIXED_PRECISION=true

# Memory optimization mode (low, medium, high)
MEMORY_OPTIMIZATION=medium

# =================================================================
# NEUROMORPHIC HARDWARE BACKENDS
# =================================================================

# Intel Loihi 2 Configuration
LOIHI_ENABLED=false
LOIHI_NRC_API_KEY=your_nrc_api_key_here
LOIHI_BOARD_ID=ncl-og-05
LOIHI_NUM_CHIPS=2

# BrainChip Akida Configuration  
AKIDA_ENABLED=false
AKIDA_RUNTIME_LICENSE=your_akida_license_key_here
AKIDA_DEVICE_ID=0

# =================================================================
# EVENT CAMERA CONFIGURATION
# =================================================================

# Default event camera type (dvs128, davis346, prophesee, simulation)
EVENT_CAMERA_TYPE=simulation

# DVS128 Configuration
DVS128_DEVICE_PATH=/dev/ttyUSB0
DVS128_BAUDRATE=4000000

# DAVIS346 Configuration
DAVIS346_DEVICE_ID=0
DAVIS346_USB_BUFFER_SIZE=8192

# Prophesee Configuration
PROPHESEE_PLUGIN_PATH=/usr/local/lib/prophesee
PROPHESEE_DEVICE_SERIAL=your_camera_serial_here

# Simulation Configuration
SIMULATION_DATA_PATH=./datasets/simulation
SIMULATION_NOISE_LEVEL=0.1
SIMULATION_FRAME_RATE=1000

# =================================================================
# MODEL CONFIGURATION
# =================================================================

# Default model architecture (spiking_yolo, spiking_resnet, custom)
DEFAULT_MODEL=spiking_yolo

# Model checkpoint directory
MODEL_CHECKPOINT_DIR=./checkpoints

# Pre-trained models cache directory
PRETRAINED_MODELS_DIR=./models

# Model quantization (int8, int4, fp16, fp32)
MODEL_QUANTIZATION=fp16

# =================================================================
# TRAINING CONFIGURATION
# =================================================================

# Default batch size
BATCH_SIZE=32

# Number of training epochs
MAX_EPOCHS=100

# Learning rate
LEARNING_RATE=0.001

# Number of time steps for SNN processing
TIME_STEPS=10

# Surrogate gradient function (fast_sigmoid, atan, triangular)
SURROGATE_GRADIENT=fast_sigmoid

# =================================================================
# DATA CONFIGURATION
# =================================================================

# Dataset root directory
DATASET_ROOT=./datasets

# Supported datasets (n-cars, n-caltech101, ddd17, gen1)
DEFAULT_DATASET=n-cars

# Data preprocessing workers
NUM_WORKERS=4

# Enable data augmentation
ENABLE_AUGMENTATION=true

# Event accumulation time window (in microseconds)
EVENT_TIME_WINDOW=50000

# =================================================================
# MONITORING AND LOGGING
# =================================================================

# Enable Weights & Biases logging
WANDB_ENABLED=false
WANDB_PROJECT=spike-snn-event-vision
WANDB_API_KEY=your_wandb_api_key_here

# Enable TensorBoard logging
TENSORBOARD_ENABLED=true
TENSORBOARD_LOG_DIR=./logs/tensorboard

# Prometheus metrics endpoint
PROMETHEUS_ENABLED=false
PROMETHEUS_PORT=8090

# Model performance monitoring
ENABLE_PROFILING=false
PROFILING_OUTPUT_DIR=./logs/profiling

# =================================================================
# ROS2 INTEGRATION
# =================================================================

# Enable ROS2 integration
ROS2_ENABLED=false

# ROS2 domain ID
ROS_DOMAIN_ID=0

# Event topic name
EVENT_TOPIC=/dvs/events

# Detection output topic
DETECTION_TOPIC=/snn/detections

# ROS2 QoS profile (best_effort, reliable)
ROS2_QOS_PROFILE=best_effort

# =================================================================
# API AND WEB INTERFACE
# =================================================================

# Enable REST API
API_ENABLED=false
API_HOST=0.0.0.0
API_PORT=8000

# API authentication
API_AUTHENTICATION=false
API_SECRET_KEY=your_secret_key_here

# Enable web dashboard
DASHBOARD_ENABLED=false
DASHBOARD_PORT=8080

# =================================================================
# STORAGE AND CACHING
# =================================================================

# Cache directory for temporary files
CACHE_DIR=./cache

# Maximum cache size (in GB)
MAX_CACHE_SIZE=10

# Database configuration (for experiment tracking)
DATABASE_URL=sqlite:///./experiments.db

# File storage backend (local, s3, gcs)
STORAGE_BACKEND=local

# S3 Configuration (if using S3 backend)
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
AWS_BUCKET_NAME=spike-snn-models
AWS_REGION=us-west-2

# =================================================================
# SECURITY CONFIGURATION
# =================================================================

# Enable secure mode (additional security checks)
SECURE_MODE=false

# API rate limiting (requests per minute)
API_RATE_LIMIT=100

# Maximum file upload size (in MB)
MAX_UPLOAD_SIZE=100

# Allowed file extensions for uploads
ALLOWED_EXTENSIONS=.onnx,.pth,.h5,.pb

# =================================================================
# PERFORMANCE TUNING
# =================================================================

# Number of inference threads
INFERENCE_THREADS=4

# Event buffer size (number of events)
EVENT_BUFFER_SIZE=100000

# Enable asynchronous processing
ASYNC_PROCESSING=true

# Memory mapping for large datasets
ENABLE_MEMORY_MAPPING=true

# =================================================================
# EXPERIMENTAL FEATURES
# =================================================================

# Enable experimental features (may be unstable)
ENABLE_EXPERIMENTAL=false

# Quantum-enhanced processing (experimental)
QUANTUM_BACKEND=false

# Advanced attention mechanisms
ATTENTION_MECHANISM=false

# Federated learning support
FEDERATED_LEARNING=false

# =================================================================
# DEPLOYMENT CONFIGURATION
# =================================================================

# Deployment environment (development, staging, production)
DEPLOYMENT_ENV=development

# Enable health checks
HEALTH_CHECK_ENABLED=true
HEALTH_CHECK_INTERVAL=30

# Graceful shutdown timeout (seconds)
SHUTDOWN_TIMEOUT=10

# =================================================================
# EXAMPLE CONFIGURATIONS
# =================================================================

# Example: High-performance training setup
# DEVICE=cuda
# CUDA_DEVICE_ID=0
# ENABLE_MIXED_PRECISION=true
# BATCH_SIZE=64
# NUM_WORKERS=8
# TENSORBOARD_ENABLED=true
# WANDB_ENABLED=true

# Example: Low-power edge deployment
# DEVICE=cpu
# MODEL_QUANTIZATION=int8
# MEMORY_OPTIMIZATION=high
# ASYNC_PROCESSING=false
# BATCH_SIZE=1

# Example: Neuromorphic hardware deployment
# LOIHI_ENABLED=true
# DEVICE=loihi
# MODEL_QUANTIZATION=int4
# TIME_STEPS=5
# BATCH_SIZE=16